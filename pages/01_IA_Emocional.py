import streamlit as st
import sys

st.set_page_config(
    page_title="IA Emocional",
    page_icon="ğŸ§ ",
    layout="centered"
)

st.title("ğŸ§  IA Emocional - Detector de Estado Cognitivo")

# =====================================================
# FUNÃ‡ÃƒO: verifica se estÃ¡ rodando local ou cloud
# =====================================================
def rodando_no_cloud():
    return not sys.platform.startswith("win") and not sys.platform.startswith("darwin")

# =====================================================
# TENTATIVA DE IMPORTAÃ‡ÃƒO (somente local)
# =====================================================
if rodando_no_cloud():
    st.warning("âš ï¸ Este recurso nÃ£o Ã© suportado no Streamlit Cloud.")
    st.info(
        """
        ğŸ”’ **LimitaÃ§Ãµes do ambiente Cloud**
        - Webcam nÃ£o disponÃ­vel
        - MediaPipe nÃ£o suportado
        
        ğŸ‘‰ Execute este mÃ³dulo **localmente** para usar o detector emocional.
        """
    )

    st.markdown("### ğŸ’» Como executar localmente:")
    st.code(
        "pip install opencv-python mediapipe streamlit\n"
        "streamlit run app.py",
        language="bash"
    )

    st.stop()

# =====================================================
# IMPORTAÃ‡Ã•ES LOCAIS (SÃ“ EXECUTAM NO PC)
# =====================================================
try:
    import cv2
    import mediapipe as mp
    import numpy as np
except Exception as e:
    st.error("Erro ao carregar bibliotecas locais.")
    st.exception(e)
    st.stop()

# =====================================================
# MEDIA PIPE
# =====================================================
mp_face_mesh = mp.solutions.face_mesh
face_mesh = mp_face_mesh.FaceMesh(
    max_num_faces=1,
    refine_landmarks=True,
    min_detection_confidence=0.5,
    min_tracking_confidence=0.5,
)

# =====================================================
# FUNÃ‡ÃƒO: ClassificaÃ§Ã£o simples de estado cognitivo
# =====================================================
def classificar_estado(piscar, abertura_olhos):
    if piscar > 20:
        return "ğŸ˜´ Fadiga"
    elif abertura_olhos < 0.015:
        return "ğŸ˜ Baixa AtenÃ§Ã£o"
    else:
        return "ğŸ™‚ Normal"

# =====================================================
# INTERFACE
# =====================================================
st.success("âœ… Ambiente local detectado. Webcam habilitada.")

iniciar = st.button("ğŸ“· Iniciar DetecÃ§Ã£o")

if iniciar:
    cap = cv2.VideoCapture(0)

    stframe = st.empty()
    status = st.empty()

    piscadas = 0

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        resultado = face_mesh.process(rgb)

        abertura_olhos = 0.02  # valor padrÃ£o

        if resultado.multi_face_landmarks:
            landmarks = resultado.multi_face_landmarks[0].landmark

            olho_sup = landmarks[159].y
            olho_inf = landmarks[145].y
            abertura_olhos = abs(olho_sup - olho_inf)

            if abertura_olhos < 0.01:
                piscadas += 1

        estado = classificar_estado(piscadas, abertura_olhos)

        cv2.putText(
            frame,
            f"Estado: {estado}",
            (30, 40),
            cv2.FONT_HERSHEY_SIMPLEX,
            1,
            (0, 255, 0),
            2,
        )

        stframe.image(frame, channels="BGR")
        status.markdown(f"### Estado Cognitivo: **{estado}**")

    cap.release()
